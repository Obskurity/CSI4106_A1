{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSI 4106 Introduction to Artificial Intelligence** <br/>\n",
    "*Assignment 1: Data Preparation*\n",
    "\n",
    "# Identification\n",
    "\n",
    "Name: Arthur Wang <br/>\n",
    "Student Number: 300185298\n",
    "\n",
    "# Exploratory Analysis\n",
    "\n",
    "## Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset\n",
    "\n",
    "As outlined in the project description, it should be possible for the correctors to ecute your notebook without requiring any downloads.\n",
    "\n",
    "To facilitate access to the dataset without the need for downloads, use the data ovided in the public GitHub repository and provide a link to the raw version of the taset.\n",
    "\n",
    "The link to the raw version is as follows:\n",
    "\n",
    "*https://raw.githubusercontent.com/GITHUB_USERNAME/REPOSITORY_NAME/main/DATASETNAME.v*\n",
    "\n",
    "For example:\n",
    "\n",
    "[https://github.com/turcotte/csi4106-f24/blob/main/assignments-data/a1/01/glass.csv]ttps://github.com/turcotte/csi4106-f24/blob/main/assignments-data/a1/01/glass.csv)\n",
    "\n",
    "Now provide the link to YOUR dataset and read the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_id_url = \"https://raw.githubusercontent.com/Obskurity/CSI4106_A1/main/01/glass.csv\"\n",
    "glass_id_dataset = pd.read_csv(glass_id_url)\n",
    "\n",
    "dermatology_url = \"https://raw.githubusercontent.com/Obskurity/CSI4106_A1/main/02/dermatology_database_1.csv\"\n",
    "dermatology_dataset = pd.read_csv(dermatology_url)\n",
    "\n",
    "mhr_url = \"https://raw.githubusercontent.com/Obskurity/CSI4106_A1/main/03/Maternal%20Health%20Risk%20Data%20Set.csv\"\n",
    "mhr_dataset = pd.read_csv(mhr_url)\n",
    "\n",
    "car_url = \"https://raw.githubusercontent.com/Obskurity/CSI4106_A1/main/04/car.data\"\n",
    "car_dataset = pd.read_csv(car_url)\n",
    "\n",
    "wq_url = \"https://raw.githubusercontent.com/Obskurity/CSI4106_A1/main/05/WineQT.csv\"\n",
    "wq_dataset = pd.read_csv(wq_url)\n",
    "\n",
    "sixteen_p_url = \"https://raw.githubusercontent.com/Obskurity/CSI4106_A1/main/06/16P.csv\"\n",
    "sixteen_p_dataset = pd.read_csv(sixteen_p_url, encoding='ISO-8859-1')\n",
    "\n",
    "# using training set only since it has sufficient data\n",
    "cs_url = \"https://raw.githubusercontent.com/Obskurity/CSI4106_A1/main/07/train.csv\"\n",
    "cs_dataset = pd.read_csv(cs_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    "The following are the questions for Assignment 1. Under each question, we have provided an initial code cell. You are encouraged to add additional code cells to maintain logical separation of your code. For instance, place the definition of a function in one cell and its execution in a subsequent cell. This approach will help preserve clarity and enhance readability by avoiding the inclusion of excessive code within a single cell.\n",
    "\n",
    "1. **Analysis of Missing Values**: Examine the datasets to identify and assess ssing values in various attributes. Missing values may be represented by symbols ch as '?', empty strings, or other placeholders.\n",
    "\n",
    "    1.1 In the list of options, what are the datasets that contain missing values? ecifically, which attribute or attributes has missing values?\n",
    "\n",
    "    1.2 Describe the methodology used for this investigation, and provide the rresponding code.\n",
    "\n",
    "    1.1 Data imputation involves replacing missing or incomplete data with substituted values to preserve the dataset's integrity for subsequent analysis. Propose imputation strategies for each attribute with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n",
    "# 1.1a - Finding out which datasets have missing values\n",
    "# missing attribute values: None (dataset origin says so)\n",
    "glass_missing = glass_id_dataset.isnull().sum().sum()\n",
    "print(\"Missing [null] values glass identification dataset:\", glass_missing)\n",
    "question_mark_count = (glass_id_dataset == '?').sum().sum()\n",
    "print(\"Missing [question mark] values glass identification dataset:\", question_mark_count)\n",
    "glass_missing += question_mark_count\n",
    "print(\"Total missing values glass dataset:\", glass_missing)\n",
    "\n",
    "# missing values represented with '?' (dataset origin says so)\n",
    "dermatology_missing = dermatology_dataset.isnull().sum().sum()\n",
    "print(\"\\nMissing [null] values dermatology dataset:\", dermatology_missing)\n",
    "question_mark_count = (dermatology_dataset == '?').sum().sum()\n",
    "print(\"Missing [question mark] values dermatology dataset:\", question_mark_count)\n",
    "dermatology_missing += question_mark_count\n",
    "print(\"Total missing values dermatology dataset:\", dermatology_missing)\n",
    "\n",
    "# has no missing values (dataset origin says so)\n",
    "mhr_missing = mhr_dataset.isnull().sum().sum()\n",
    "print(\"\\nMissing [null] values maternal health risk dataset:\", mhr_missing)\n",
    "question_mark_count = (mhr_dataset == '?').sum().sum()\n",
    "print(\"Missing [question mark] values maternal health risk dataset:\", question_mark_count)\n",
    "mhr_missing += question_mark_count\n",
    "print(\"Total missing values mhr dataset:\", mhr_missing)\n",
    "\n",
    "# has no missing values (dataset origin says so)\n",
    "car_missing = car_dataset.isnull().sum().sum()\n",
    "print(\"\\nMissing [null] values car dataset:\", car_missing)\n",
    "question_mark_count = (car_dataset == '?').sum().sum()\n",
    "print(\"Missing [question] values car dataset:\", question_mark_count)\n",
    "car_missing += question_mark_count\n",
    "print(\"Total missing values car dataset:\", car_missing)\n",
    "\n",
    "# wine quality dataset\n",
    "wq_missing = wq_dataset.isnull().sum().sum()\n",
    "print(\"\\nMissing [null] values wine quality dataset:\", wq_missing)\n",
    "question_mark_count = (wq_dataset == '?').sum().sum()\n",
    "print(\"Missing [question mark] values wine quality dataset:\", question_mark_count)\n",
    "wq_missing += question_mark_count\n",
    "print(\"Total missing values wq dataset:\", wq_missing)\n",
    "\n",
    "# 16 personalities dataset\n",
    "sixteen_p_missing = sixteen_p_dataset.isnull().sum().sum()\n",
    "print(\"\\nMissing [null] values 16p dataset:\", sixteen_p_missing)\n",
    "question_mark_count = (sixteen_p_dataset == '?').sum().sum()\n",
    "print(\"Missing [question mark] values 16p dataset:\", question_mark_count)\n",
    "sixteen_p_missing += question_mark_count\n",
    "print(\"Total missing values 16p dataset:\", sixteen_p_missing)\n",
    "\n",
    "# credit score dataset\n",
    "cs_missing = cs_dataset.isnull().sum().sum()\n",
    "print(\"\\nMissing [null] values cs dataset:\", cs_missing)\n",
    "question_mark_count = (cs_dataset == '?').sum().sum()\n",
    "print(\"Missing [question mark] values cs dataset:\", question_mark_count)\n",
    "cs_missing  += question_mark_count\n",
    "print(\"Total missing values cs dataset:\", cs_missing)\n",
    "\n",
    "# 1.1b - which attributes have missing value\n",
    "# As we can observe from the previous results, the dermatology and credit score have missing values\n",
    "# we know that the credit score dataset only has missing values that are null\n",
    "missing_attributes_cs = cs_dataset.columns[cs_dataset.isnull().any()]\n",
    "print(\"\\nAttribute(s) with missing values for credit score dataset: \", missing_attributes_cs)\n",
    "\n",
    "# we know that the credit score dataset only has missing values that are '?'\n",
    "missing_attributes_dermatology = dermatology_dataset.columns[(dermatology_dataset == '?').any()]\n",
    "print(\"Attribute(s) with missing values for dermatology dataset: \", missing_attributes_dermatology)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Select and familiarize yourself with a classification task:** Choose one of e provided datasets for further investigation. It is advisable to select a dataset ntaining a sufficiently large number of examples, ideally around 1,000, to ensure bust results when applying machine learning algorithms in the subsequent assignment.\n",
    "\n",
    "    2.1 What is the objective of the task? Is it intended for a specific plication? Do you possess expertise in this particular domain of application?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Attribute Analysis**: \n",
    "\n",
    "    3.1 Determine which attributes lack informativeness and should be excluded to prove the effectiveness of the machine learning analysis. If all features are emed relevant, explicitly state this conclusion.\n",
    "\n",
    "    3.2 Examine the distribution of each attribute (column) within the dataset. Utilize histograms or boxplots to visualize the distributions, identifying any underlying patterns or outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Class Distribution Analysis**: Investigate the distribution of class labels within the dataset. Employ bar plots to visualize the frequency of instances for each class, and assess whether the dataset is balanced or imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Preprocessing**: \n",
    "\n",
    "    5.1 For numerical features, determine the best transformation to use. Indicate e transformation that seems appropriate and why. Include the code illustrating how  apply the transformation. For at least one attribute, show the distribution before d after the transformation. See [Preprocessing data](https://scikit-learn.org/able/modules/preprocessing.html).\n",
    "\n",
    "    5.2 For categorical features, show how to apply [one-hot encoding](https://ikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).  your dataset does not have categorical data, show how to apply the one-hot encoder  the label (target variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Training and target data**: Set the Python variable `X` to designate the data and `y` to designate the target class. Make sure to select only the informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Training and test sets**: Split the dataset into training and testing sets. Reserve 20% of data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------\n",
    "\n",
    "# References\n",
    "\n",
    "Make sure you provide references to ALL sources used (articles, code, algorithms).\n",
    "\n",
    "## AI transcript\n",
    "**Hint:** To share a link to your colab notebook, click on \"share\" on the top right. Then, under *General access* , change *Restricted* to \"Anyone with the link\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
